{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache-Spark\n",
    "SK T-academy <br>\n",
    "date :2020-11-27\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## Docker 띄우고 재플린으로실행하는법\n",
    "* 먼저 Docker 앱을 실행하고\n",
    "* docker ps 명령어로 확인 (+) docker도 입력해보기\n",
    "* docker 를 통해 zeppelin 이미지 가져오기\n",
    "    * docker run -p 4040:4040 -p 8080:8080 --privileged=true -v $PWD/logs:/logs -v $PWD/notebook:/notebook -e ZEPPELIN_NOTEBOOK_DIR='/notebook' -e ZEPPELIN_LOG_DIR='/logs' -d apache/zeppelin:0.8.1 /zeppelin/bin/zeppelin.sh\n",
    "* zeppelin띄우려면 localhost로 띄우면됨 http://localhost:8080/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## [1] Spark의 개념과 활용\n",
    "**HDFS**\n",
    "* 큰 파일들이 잘 저장될 수 있도록\n",
    "* Master Node\n",
    "* Slave Nodes\n",
    "\n",
    "**Spark**\n",
    "* 기존 맵리듀스보다 더 빠르게 실행되도록하는게 목적\n",
    "* 하둡이 있는경우, spark를 올리면 쉽게 가능.\n",
    "* structred data : Schema가 있는 데이터를 의미\n",
    "* 머신러닝 라이브러리도 제공함\n",
    "* 이런 ecosystem이 다양해서 영향력이 있음.\n",
    "\n",
    "**MapReduce vs Spark 차이점**\n",
    "* MapReduce 방식\n",
    "    * 데이터 읽고, 쓰고를 반복함\n",
    "    * iteration돌때마다 읽고 쓰고를 반복\n",
    "    * HDFS에서 결과를 읽어서 return하는 방식\n",
    "* Spark방식\n",
    "    * 인메모리에서 다 처리하는 방식\n",
    "    * 디스크기준 10배, 분산 인메모리 이용했을때는 100배이상 빠름.\n",
    "    * scala기반으로 개발되어있음.\n",
    "    * 개발의 생산성 측면에서도 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hadoop & Spark**\n",
    "* Hadoop (HDFS, MapReduce)\n",
    "* Spark\n",
    "    * MapReduce의 확장. \n",
    "    * Machine-Learning tast에 유리함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## [2] Spark실시간 배치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Processing\n",
    "    * 크고 복잡함\n",
    "* Stream Processing\n",
    "     * 데이터를 바로 즉시 처리하는것\n",
    "* Micro-Batching\n",
    "    * 스몰 배치사이즈 (batch+streaming)\n",
    "    * Spark가 여기에 해당\n",
    "    \n",
    "* Spark Streaming은 개발은 어렵지않은데, 운영이 힘든편..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## [3] Spark 실습코드\n",
    "* flightData2015.createOrReplaceTempView(\"flight_data_2015\")\n",
    "    * //SQL을 사용하기 위해 임시 view만들기\n",
    "    \n",
    "* val pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "    * //각 제품의 각 국가로 수출 된 총 금액을 얻으려면 제품 별 그룹화, 국가 별 피봇 팅 및 금액 합계를 얻어온다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "* collect, count, save할경우만 실제 spark가 액션을하는거고, map, filter, groupby, join할땐 스파크는 일을 안함.\n",
    "    * Transformations (RDD를 새로 생성)\n",
    "    * Actions(driver program에 액션)\n",
    "    \n",
    "* RDDs vs DataFrames\n",
    "    * 언어가 python이든 spark이든 DataFrame을 사용하게되면 성능은 동일함.\n",
    "    * RDD에서는 python, scala가 성능차이많이남\n",
    "    * DataFrame의강점은 Schema를 갖고있어서 직관적. \n",
    "* Structured API Overview\n",
    "    * SQL\n",
    "    * DataFrame\n",
    "    * Datasets\n",
    "* Optimization\n",
    "    * spark는 알아서 최적화를 함.\n",
    "    * Hive에서는 잘 도는데 spark로하면 잘안되는 경우도있는데, 그런경우 spark이 알아서 최적화를 한건데 그럼 꺼주거나 했던 경험이 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* UDF함수 : 02.stapi05.scala파일에있음\n",
    "* TempView관련 : 02.stapi08.scala파일에있음\n",
    "* BI로 시각화해서 빨리 보여줘야할때 SparkSQL을 쓰고 그외에는 Hive로 처리\n",
    "* df.cache()  를 해놔야 불러올때 시간 줄일 수 있음\n",
    "* Spark 재플린에서 TempView, TempTable을 선언하면 게속 사용가능한데 대신에 spark session을 닫으면 없어짐\n",
    "* RDD는 더이상 안써도될거같고, 대부분 DataFrame으로가능. json데이터 처리할때만 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
